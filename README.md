# Smart City - Backend

Ce projet est le backend d'une application Smart City. Il fournit une API RESTful pour acc√©der aux donn√©es et aux pr√©dictions relatives √† la qualit√© de l'air et √† la m√©t√©o, ainsi qu'un syst√®me d'alerte automatis√©. L'application est enti√®rement conteneuris√©e avec Docker pour une installation et un d√©ploiement simplifi√©s.

-----

## üìã Features

  * **API RESTful compl√®te** : Construite avec Django et Django REST Framework.
  * **Authentification JWT** : Syst√®me d'inscription, de connexion, de d√©connexion et de rafra√Æchissement de token s√©curis√©.
  * **Qualit√© de l'Air** :
      * Int√©gration avec l'API OpenWeatherMap pour r√©cup√©rer les donn√©es de qualit√© de l'air actuelles et historiques.
      * Pr√©diction de l'indice de qualit√© de l'air (AQI) √† l'aide d'un mod√®le **LSTM (Long Short-Term Memory)** entra√Æn√© avec PyTorch.
      * Endpoints pour consulter les donn√©es de qualit√© de l'air r√©centes.
  * **Pr√©dictions M√©t√©o** :
      * Int√©gration avec l'API M√©t√©o France pour obtenir des donn√©es climatologiques historiques.
      * Entra√Ænement de mod√®les de pr√©diction m√©t√©o (**XGBoost**) pour diverses caract√©ristiques (temp√©rature max/min, pr√©cipitations, etc.).
      * API pour obtenir des pr√©dictions m√©t√©o √† plusieurs jours.
  * **Syst√®me d'Alertes Automatis√©** :
      * T√¢ches planifi√©es (cron jobs) pour v√©rifier en continu si les seuils de polluants atmosph√©riques sont d√©pass√©s.
      * Cr√©ation automatique d'alertes en base de donn√©es lorsque les seuils sont atteints.
  * **T√¢ches Asynchrones** : Utilisation d'APScheduler pour ex√©cuter des t√¢ches en arri√®re-plan, comme la r√©cup√©ration de donn√©es et la v√©rification des alertes, sans bloquer le serveur web.
  * **Containerisation** : Configuration compl√®te avec `Dockerfile` et `docker-compose.yml` pour un d√©ploiement facile et reproductible.
  * **Documentation d'API** : G√©n√©ration automatique de la documentation interactive avec Swagger (OpenAPI) et ReDoc.

-----

## üèóÔ∏è Architecture

Le projet est con√ßu autour d'une architecture de microservices g√©r√©e par Docker Compose, comprenant :

1.  **`web`** : Le service principal qui ex√©cute l'application Django avec un serveur Gunicorn. Il expose l'API RESTful pour les interactions avec les clients.
2.  **`scheduler`** : Un service d√©di√© qui ex√©cute les t√¢ches planifi√©es (via `APScheduler`) pour la r√©cup√©ration de donn√©es et le syst√®me d'alerte. Il garantit que les t√¢ches de fond n'impactent pas les performances de l'API.
3.  **Base de donn√©es** : Le syst√®me est configur√© pour se connecter √† une base de donn√©es PostgreSQL, qui doit √™tre fournie en tant que service distinct (non incluse dans ce `docker-compose.yml`).

Les mod√®les de Machine Learning sont pr√©-entra√Æn√©s ou peuvent √™tre entra√Æn√©s via des commandes de gestion Django et sont ensuite charg√©s en m√©moire par les services pour effectuer des pr√©dictions en temps r√©el.

-----

## üõ†Ô∏è Technologies Utilis√©es

  * **Backend** : Django, Django REST Framework
  * **Base de Donn√©es** : PostgreSQL
  * **Machine Learning** : PyTorch, Scikit-learn, XGBoost, Pandas, NumPy
  * **Containerisation** : Docker, Docker Compose
  * **Serveur WSGI** : Gunicorn 
  * **Planification de T√¢ches** : APScheduler
  * **Documentation API** : drf-yasg (Swagger/OpenAPI)
  * **Authentification** : djangorestframework-simplejwt 

-----

## üöÄ Installation et Lancement

### Pr√©requis

  * Docker
  * Docker Compose

### 1\. Cloner le D√©p√¥t

```bash
git clone <URL_DU_DEPOT>
cd projet-annuel-esgi-aliabd-back-end
```

### 2\. Configurer les Variables d'Environnement

Cr√©ez un fichier `.env` √† la racine du projet en copiant le mod√®le `env.example` (s'il existe) ou en le cr√©ant manuellement. Remplissez les variables n√©cessaires :

```env
# Cl√© secr√®te de Django (g√©n√©rez une cha√Æne al√©atoire forte)
SECRET_KEY=votre_super_cle_secrete

# Configuration de la base de donn√©es PostgreSQL
DB_NAME=postgres
DB_USER=votre_user
DB_PASSWORD=votre_mot_de_passe
DB_HOST=host.docker.internal # ou l'IP de votre service de base de donn√©es
DB_PORT=5432

# Mode Debug (mettre √† False en production)
DEBUG=True

# Cl√©s d'API externes
OPENWEATHERMAP_API_KEY=votre_cle_api_openweathermap
METEOFRANCE_API_KEY=votre_cle_api_meteofrance
```

### 3\. Lancer l'Application

Utilisez Docker Compose pour construire et d√©marrer les conteneurs en arri√®re-plan.

```bash
docker-compose up --build -d
```

L'API sera alors accessible sur `http://localhost:3000`.

-----

## üí° Utilisation du Projet

### Documentation de l'API

Une fois l'application lanc√©e, vous pouvez acc√©der √† la documentation interactive de l'API pour voir tous les endpoints disponibles et les tester directement depuis votre navigateur :

  * **Swagger UI** : `http://localhost:3000/swagger/`
  * **ReDoc** : `http://localhost:3000/redoc/`

### Commandes de Gestion

Plusieurs commandes sont disponibles pour g√©rer l'application et les mod√®les d'IA. Ex√©cutez-les √† l'int√©rieur du conteneur `web`.

  * **Appliquer les migrations de la base de donn√©es** (normalement fait au d√©marrage ) :

    ```bash
    docker-compose exec web python manage.py migrate
    ```

  * **Importer les donn√©es historiques de qualit√© de l'air** (pour les 6 derniers mois) :

    ```bash
    docker-compose exec web python manage.py import_aq
    ```

  * **Entra√Æner les mod√®les de pr√©diction m√©t√©o** :

    ```bash
    # Entra√Æner les mod√®les par d√©faut (TX, TN, RR, TM, TAMPLI)
    docker-compose exec web python manage.py train_weather_models 

    # Entra√Æner pour une caract√©ristique sp√©cifique (ex: temp√©rature maximale 'TX')
    docker-compose exec web python manage.py train_weather_models --features TX
    ```

### T√¢ches Planifi√©es

Le service `scheduler` ex√©cute automatiquement les t√¢ches suivantes toutes les heures:

  * `fetch_latest_air` : R√©cup√®re la derni√®re heure de donn√©es sur la qualit√© de l'air.
  * `check_alerts` : V√©rifie les donn√©es actuelles de qualit√© de l'air par rapport aux seuils d'alerte d√©finis.
